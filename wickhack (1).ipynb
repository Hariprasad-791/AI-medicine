{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPCHrCK0QUO24wNtunHgiVr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5EHzkogOuN6w","executionInfo":{"status":"ok","timestamp":1734784448424,"user_tz":-330,"elapsed":5051,"user":{"displayName":"Hariprasad B R","userId":"18433760805538358115"}},"outputId":"87b32626-2301-46a4-92a8-e17f3f60776d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}],"source":["# Install necessary libraries\n","!pip install numpy pandas scikit-learn tensorflow"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Lambda, BatchNormalization\n","from tensorflow.keras.models import Model\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import classification_report\n","import pickle\n"],"metadata":{"id":"3bwFG2kzB8SH","executionInfo":{"status":"ok","timestamp":1734787715185,"user_tz":-330,"elapsed":392,"user":{"displayName":"Hariprasad B R","userId":"18433760805538358115"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Generate synthetic dataset\n","np.random.seed(42)\n","\n","# Normal and anomalous data\n","normal_data = np.random.normal(loc=0.5, scale=0.1, size=(900, 10))\n","anomaly_data = np.random.normal(loc=1.0, scale=0.1, size=(100, 10))\n","\n","# Combine and label\n","data = np.vstack([normal_data, anomaly_data])\n","labels = np.array([0] * 900 + [1] * 100)\n","\n","# Normalize the dataset\n","scaler = MinMaxScaler()\n","data = scaler.fit_transform(data)\n","\n","# Split into train and test sets\n","X_train = data[:800]  # 800 samples for training\n","X_test = data[800:]   # Remaining 200 samples for testing\n","y_test = labels[800:] # True labels for X_test\n"],"metadata":{"id":"dsk9M_usE5dI","executionInfo":{"status":"ok","timestamp":1734787725866,"user_tz":-330,"elapsed":404,"user":{"displayName":"Hariprasad B R","userId":"18433760805538358115"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Define the latent space dimension\n","latent_dim = 2\n","\n","# Encoder\n","inputs = Input(shape=(10,), name=\"encoder_input\")\n","x = Dense(64, activation='relu')(inputs)\n","x = BatchNormalization()(x)\n","x = Dense(32, activation='relu')(x)\n","x = BatchNormalization()(x)\n","\n","z_mean = Dense(latent_dim, name=\"z_mean\")(x)\n","z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n","\n","def sampling(args):\n","    z_mean, z_log_var = args\n","    epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim), mean=0., stddev=1.0)\n","    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","\n","z = Lambda(sampling, output_shape=(latent_dim,), name=\"z\")([z_mean, z_log_var])\n","\n","# Decoder\n","decoder_inputs = Input(shape=(latent_dim,), name=\"decoder_input\")\n","x = Dense(32, activation='relu')(decoder_inputs)\n","x = BatchNormalization()(x)\n","x = Dense(64, activation='relu')(x)\n","x = BatchNormalization()(x)\n","outputs = Dense(10, activation='sigmoid', name=\"decoder_output\")(x)\n","\n","# Encoder and Decoder models\n","encoder = Model(inputs, [z_mean, z_log_var, z], name=\"encoder\")\n","decoder = Model(decoder_inputs, outputs, name=\"decoder\")\n","\n","# Full VAE model\n","vae_outputs = decoder(encoder(inputs)[2])\n","\n","# Define custom VAE model with integrated loss\n","class VAE(Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var, z = self.encoder(inputs)\n","        reconstructed = self.decoder(z)\n","        # Reconstruction loss\n","        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.square(inputs - reconstructed), axis=1))\n","        # KL divergence loss\n","        kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))\n","        self.add_loss(reconstruction_loss + kl_loss)\n","        return reconstructed\n","\n","vae = VAE(encoder, decoder)\n","vae.compile(optimizer=tf.keras.optimizers.Adam())\n"],"metadata":{"id":"92-CfIt1FJK8","executionInfo":{"status":"ok","timestamp":1734787738803,"user_tz":-330,"elapsed":378,"user":{"displayName":"Hariprasad B R","userId":"18433760805538358115"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["vae.fit(X_train, X_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_HNiRMtOQ-O","executionInfo":{"status":"ok","timestamp":1734787766600,"user_tz":-330,"elapsed":13367,"user":{"displayName":"Hariprasad B R","userId":"18433760805538358115"}},"outputId":"c8ef6a7b-b0da-4b36-ac64-76b8614a8bce"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.3943 - val_loss: 0.1927\n","Epoch 2/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1741 - val_loss: 0.1234\n","Epoch 3/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1186 - val_loss: 0.1202\n","Epoch 4/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1039 - val_loss: 0.1119\n","Epoch 5/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1020 - val_loss: 0.1015\n","Epoch 6/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0993 - val_loss: 0.1048\n","Epoch 7/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0978 - val_loss: 0.1013\n","Epoch 8/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0954 - val_loss: 0.1025\n","Epoch 9/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0953 - val_loss: 0.1004\n","Epoch 10/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0952 - val_loss: 0.0992\n","Epoch 11/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0934 - val_loss: 0.0987\n","Epoch 12/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0924 - val_loss: 0.1000\n","Epoch 13/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0930 - val_loss: 0.1006\n","Epoch 14/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0912 - val_loss: 0.1005\n","Epoch 15/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.1001\n","Epoch 16/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0941 - val_loss: 0.1003\n","Epoch 17/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0933 - val_loss: 0.0995\n","Epoch 18/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0942 - val_loss: 0.0998\n","Epoch 19/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0923 - val_loss: 0.0997\n","Epoch 20/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0951 - val_loss: 0.0993\n","Epoch 21/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0929 - val_loss: 0.1001\n","Epoch 22/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0946 - val_loss: 0.1007\n","Epoch 23/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0941 - val_loss: 0.1005\n","Epoch 24/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0905 - val_loss: 0.0996\n","Epoch 25/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0916 - val_loss: 0.0988\n","Epoch 26/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0922 - val_loss: 0.1010\n","Epoch 27/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0920 - val_loss: 0.0996\n","Epoch 28/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0930 - val_loss: 0.0989\n","Epoch 29/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0929 - val_loss: 0.1003\n","Epoch 30/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0930 - val_loss: 0.0988\n","Epoch 31/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0996\n","Epoch 32/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0934 - val_loss: 0.0997\n","Epoch 33/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0951 - val_loss: 0.0990\n","Epoch 34/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0954 - val_loss: 0.1002\n","Epoch 35/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0942 - val_loss: 0.1006\n","Epoch 36/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0999\n","Epoch 37/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0917 - val_loss: 0.0998\n","Epoch 38/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0920 - val_loss: 0.0995\n","Epoch 39/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0941 - val_loss: 0.1000\n","Epoch 40/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0940 - val_loss: 0.0999\n","Epoch 41/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0924 - val_loss: 0.1007\n","Epoch 42/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0929 - val_loss: 0.0993\n","Epoch 43/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0935 - val_loss: 0.0992\n","Epoch 44/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0931 - val_loss: 0.0997\n","Epoch 45/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0935 - val_loss: 0.0987\n","Epoch 46/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.0999\n","Epoch 47/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0896 - val_loss: 0.0991\n","Epoch 48/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0913 - val_loss: 0.1008\n","Epoch 49/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0926 - val_loss: 0.1001\n","Epoch 50/50\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0939 - val_loss: 0.0990\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7b3f39882710>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["vae.save(\"vae_anomaly_detection_model.h5\")\n","\n","# Save scaler for deployment\n","with open(\"scaler.pkl\", \"wb\") as f:\n","    pickle.dump({\"scaler\": scaler}, f)\n","\n","print(\"Model and scaler saved successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIMPq8WQO-_Y","executionInfo":{"status":"ok","timestamp":1734787773933,"user_tz":-330,"elapsed":435,"user":{"displayName":"Hariprasad B R","userId":"18433760805538358115"}},"outputId":"091213c5-1a0a-4806-84e3-42f4d9b5af87"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Model and scaler saved successfully!\n"]}]},{"cell_type":"code","source":["# Generate a separate test dataset without labels\n","np.random.seed(42)\n","test_data = np.vstack([\n","    np.random.normal(loc=0.5, scale=0.1, size=(50, 10)),  # Normal data\n","    np.random.normal(loc=1.5, scale=0.2, size=(10, 10))   # Data with anomalies\n","])\n","\n","# Normalize the test data using the same scaler\n","test_data = scaler.transform(test_data)\n","\n","# Test the VAE on the new test dataset\n","reconstructed = vae.predict(test_data)\n","reconstruction_errors = np.mean(np.square(test_data - reconstructed), axis=1)\n","\n","# Determine threshold for anomaly detection\n","threshold = np.percentile(reconstruction_errors, 95)  # Use 95th percentile\n","\n","# Classify anomalies based on reconstruction error\n","predictions = (reconstruction_errors > threshold).astype(int)\n","\n","# Identify anomalies and highlight tuples\n","anomalous_tuples = []\n","anomalous_attributes = []\n","for i, (original, recon) in enumerate(zip(test_data, reconstructed)):\n","    if predictions[i] == 1:  # If the instance is an anomaly\n","        attribute_diff = np.abs(original - recon)\n","        significant_attributes = np.where(attribute_diff > 0.2)[0]  # Threshold for significant deviation\n","        anomalous_tuples.append((i, original))\n","        anomalous_attributes.append((i, significant_attributes))\n","\n","# Output results\n","print(\"Anomaly Detection Results:\")\n","for i, attributes in anomalous_attributes:\n","    print(f\"Instance {i} is an anomaly. Significant deviations in attributes: {attributes}\")\n","\n","# Save the test dataset and results\n","import pandas as pd\n","test_df = pd.DataFrame(test_data, columns=[f\"Feature_{i+1}\" for i in range(test_data.shape[1])])\n","test_df[\"Anomaly\"] = predictions\n","test_df.to_csv(\"test_dataset_results.csv\", index=False)\n","\n","print(\"\\nTest dataset results saved as 'test_dataset_results.csv'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_KmBY-NqgWOZ","executionInfo":{"status":"ok","timestamp":1734789421522,"user_tz":-330,"elapsed":438,"user":{"displayName":"Hariprasad B R","userId":"18433760805538358115"}},"outputId":"6427b687-5b62-466a-8d91-d0a5f7ca23d8"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n","Anomaly Detection Results:\n","Instance 55 is an anomaly. Significant deviations in attributes: [0 1 2 3 4 5 6 7 8 9]\n","Instance 57 is an anomaly. Significant deviations in attributes: [0 1 2 3 4 5 6 7 8 9]\n","Instance 58 is an anomaly. Significant deviations in attributes: [0 1 2 3 4 5 6 7 8 9]\n","\n","Test dataset results saved as 'test_dataset_results.csv'.\n"]}]},{"cell_type":"code","source":["\n","# Function to evaluate a specific tuple\n","def evaluate_tuple(input_tuple):\n","    # Normalize the input tuple using the same scaler\n","    normalized_tuple = scaler.transform([input_tuple])\n","\n","    # Reconstruct using the VAE\n","    reconstructed_tuple = vae.predict(normalized_tuple)\n","    reconstruction_error = np.mean(np.square(normalized_tuple - reconstructed_tuple))\n","\n","    # Check if it's an anomaly\n","    is_anomalous = reconstruction_error > threshold\n","    significant_attributes = np.where(np.abs(normalized_tuple - reconstructed_tuple) > 0.2)[1]\n","\n","    print(\"\\nTuple Evaluation Results:\")\n","    print(f\"Input Tuple: {input_tuple}\")\n","    print(f\"Reconstruction Error: {reconstruction_error:.4f}\")\n","    print(f\"Anomaly Status: {'Anomalous' if is_anomalous else 'Normal'}\")\n","    if is_anomalous:\n","        print(f\"Significant Deviations in Attributes: {significant_attributes.tolist()}\")\n","\n","# Example usage for a specific tuple\n","'''\n","Chemical_Composition_Compliance (%)\n","Normalized compliance percentage of the chemical composition.\n","\n","Packaging_Compliance_Score (1-10)\n","Normalized score for packaging compliance.\n","\n","Regulatory_Benchmark_Score (%)\n","Normalized regulatory compliance score.\n","\n","Predicted_Compliance_Score (%)\n","Normalized predicted compliance score by the model.\n","\n","Potency (%)\n","Normalized potency value.\n","\n","Purity (%)\n","Normalized purity value.\n","\n","Supplier_Reliability_Score (1-100)\n","Normalized reliability score for the supplier.\n","\n","Historical_Quality_Score (%)\n","Normalized historical quality score of the supplier's batches.\n","\n","Real_Time_Status (Binary)\n","Encoded real-time compliance status (e.g., 0 for non-compliant, 1 for compliant).\n","\n","Batch_Status (Binary)\n","Encoded batch status (e.g., 0 for rejected, 1 for approved).\n","*#\n","'''\n","\n","sample_tuple = [0.6, 0.7, 0.5, 0.8, 0.4, 0.9, 0.5, 0.6, 0, 1]\n","evaluate_tuple(sample_tuple)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_-XNc_5gcJy","executionInfo":{"status":"ok","timestamp":1734790077889,"user_tz":-330,"elapsed":397,"user":{"displayName":"Hariprasad B R","userId":"18433760805538358115"}},"outputId":"2fd43575-1774-4f57-8d19-e464f837006f"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\n","Tuple Evaluation Results:\n","Input Tuple: [0.6, 0.7, 0.5, 0.8, 0.4, 0.9, 0.5, 0.6, 0, 1]\n","Reconstruction Error: 0.0744\n","Anomaly Status: Normal\n"]}]}]}